#!/usr/bin/env python3
import argparse
import os
import sys
import pkg_resources as pkg
from datetime import datetime

import mkidcore
import mkidcore.config
from mkidcore.corelog import getLogger
import mkidpipeline.pipeline as pipe
import mkidpipeline.config as config
import mkidpipeline.steps as steps
import mkidpipeline.samples


def parse():
    # read in command line arguments
    parser = argparse.ArgumentParser(description='MKID Pipeline CLI')
    parser.add_argument('-o', type=str, help='An output specification file', default='out.yaml', dest='out_cfg')
    parser.add_argument('-p', type=str, help='A pipeline config file', default='pipe.yaml', dest='pipe_cfg')
    parser.add_argument('-d', type=str, help='A input config file', default='data.yaml', dest='data_cfg')
    parser.add_argument('--vet',  action='store_true', help='Check pipeline configuration and exit', default=False)
    parser.add_argument('--init', action='store_true', help='Setup the pipeline, clobbers _default.yaml as needed')
    parser.add_argument('--verbose', action='store_true', help='Verbose')
    parser.add_argument('--run-step', dest='single_step', help='Run a single named step', type=str)
    parser.add_argument('--make-dir', dest='make_paths', help='Create all needed directories', action='store_true')
    parser.add_argument('--info', dest='info', help='Report information about the configuration', action='store_true')
    parser.add_argument('--make-outputs', dest='makeout', help='Run the pipeline on the outputs', action='store_true')
    parser.add_argument('--logcfg', dest='logcfg', help='Run the pipeline on the outputs', type=str,
                        default=pkg.resource_filename('mkidpipeline', './utils/logging.yaml'))

    return parser.parse_args()


def init_pipeline():
    defstr = lambda x: f"{x}_default.yaml" if os.path.exists(f"{x}.yaml") else f"{x}.yaml"
    default_pipe_config = pipe.generate_default_config()
    with open(defstr('pipe'), 'w') as f:
        config.yaml.dump(default_pipe_config, f)

    sample_data = mkidpipeline.samples.get_sample_data()
    config.dump_dataconfig(sample_data, defstr('data'))

    sample_out = mkidpipeline.samples.get_sample_output()
    with open(defstr('out'), 'w') as f:
        config.yaml.dump(sample_out, f)


def run_step(stepname, dataset):
    try:
        pipe.PIPELINE_STEPS[stepname].fetch(dataset)
    except AttributeError:
        pass
    try:
        pipe.PIPELINE_STEPS[stepname].apply(dataset)
    except AttributeError:
        pass


if __name__ == "__main__":

    args = parse()
    getLogger('mkidcore', setup=True, logfile=f'mkidpipe_{datetime.now().strftime("%Y-%m-%d_%H%M")}.log',
              configfile=args.logcfg)
    log = getLogger('mkidpipe')

    getLogger('mkidcore.objects').setLevel('INFO')
    if args.verbose:
        getLogger('mkidpipe').setLevel('DEBUG')
        getLogger('mkidpipeline').setLevel('DEBUG')
        getLogger('mkidcore').setLevel('DEBUG')
    getLogger('mkidpipeline.steps.buildhdf').setLevel('INFO')
    getLogger('mkidpipeline.steps.wavecal').setLevel('INFO')

    if args.init:
        init_pipeline()
        sys.exit(0)

    config.configure_pipeline(args.pipe_cfg)
    outputs = config.MKIDOutputCollection(args.out_cfg, datafile=args.data_cfg)
    dataset = outputs.dataset

    if args.make_paths:
        config.make_paths(output_collection=outputs)
    missing_paths = config.verify_paths(output_collection=outputs, return_missing=True)
    if missing_paths:
        getLogger('mkidpipeline').critical(f'Required paths missing:\n\t'+'\n\t'.join(missing_paths))
        sys.exit(1)

    if args.vet:
        issue_report = outputs.validation_summary(null_success=True)
        if issue_report:
            getLogger('mkidpipeline').critical(issue_report)
        else:
            getLogger('mkidpipeline').info('Validation of output and data successful! Done')
        sys.exit(0)

    if args.info:
        config.inspect_database(detailed=args.verbose)

    if args.single_step:
        run_step(args.single_step, dataset)
        sys.exit(0)

    if args.makeout:
        # [] denote optional
        # build, meta, wave, pix -> wcs
        # build, meta, wave, pix, [flat] ->  spec
        # build, meta, [lin, wave, pix, cr, flat] -> image / movie
        # build, meta, [lin], wave, [pix, cr] -> flat
        # build, meta -> wave

        issue_report = outputs.validation_summary(null_success=True)
        if issue_report:
            getLogger('mkidpipeline').critical(issue_report)
            sys.exit(0)
        # 0
        steps.buildhdf.buildtables(outputs.input_timeranges)
        # 1
        if 'metadata' in config.config.flow:
            pipe.batch_apply_metadata(outputs)
        # 2
        if 'wavecal' in config.config.flow:
            steps.wavecal.fetch(outputs.wavecals)
            # TODO sort out why this is necessary for Pools to work despite __getstate__
            steps.wavecal._loaded_solutions = {}
            getLogger('mkidpipeline').setLevel('DEBUG')
            pipe.batch_applier(steps.wavecal.apply, outputs.to_wavecal)
        # 4
        if 'pixcal' in config.config.flow:
            pipe.batch_applier(steps.pixcal.apply, outputs.to_pixcal)
        if 'lincal' in config.config.flow:
            pipe.batch_applier(steps.lincal.apply, outputs.to_lincal)
        if 'cosmiccal' in config.config.flow:
            pipe.batch_applier(steps.cosmiccal.apply, list(outputs.to_cosmiccal)[:1])

        if 'flatcal' in config.config.flow:
            # 5
            steps.flatcal.fetch(list(outputs.flatcals)[:1])
            # 6
            pipe.batch_applier(steps.flatcal.apply, list(outputs.to_flatcal)[:1])

        if 'wcscal' in config.config.flow:
            steps.wcscal.fetch(outputs.wcscals)
        # 7
        steps.output.generate(outputs)
        # 8
        if 'speccal' in config.config.flow:
            steps.speccal.fetch(outputs.speccals)
