#!/usr/bin/env python3
import argparse
import os
import sys
import pkg_resources as pkg
from datetime import datetime

import mkidcore
import mkidcore.config
from mkidcore.corelog import getLogger
import mkidpipeline.pipeline as pipe
import mkidpipeline.config as config
import mkidpipeline.steps as steps

if __name__ == "__main__":
    # read in command line arguments
    parser = argparse.ArgumentParser(description='MKID Pipeline CLI')
    parser.add_argument('-o', type=str, help='An output specification file', default='out.yaml', dest='out_cfg')
    parser.add_argument('-p', type=str, help='A pipeline config file', default='pipe.yaml', dest='pipe_cfg')
    parser.add_argument('-d', type=str, help='A input config file', default='data.yaml', dest='data_cfg')
    parser.add_argument('--vet',  action='store_true', help='Check pipeline configuration', default=False)
    parser.add_argument('--init', action='store_true', help='Setup the pipeline, clobbers _default.yaml as needed')
    parser.add_argument('--verbose', action='store_true', help='Verbose')
    parser.add_argument('--run-step', dest='single_step', help='Run a single named step', type=str)
    parser.add_argument('--make-dir', dest='make_paths', help='Create all needed directories', action='store_true')
    parser.add_argument('--info', dest='info', help='Report information about the configuration', action='store_true')
    parser.add_argument('--make-outputs', dest='makeout', help='Run the pipeline on the outputs', action='store_true')
    parser.add_argument('--logcfg', dest='logcfg', help='Run the pipeline on the outputs', type=str,
                        default=pkg.resource_filename('mkidpipeline', './utils/logging.yaml'))

    args = parser.parse_args()
    getLogger('mkidcore', setup=True, logfile=f'mkidpipe_{datetime.now().strftime("%Y-%m-%d_%H%M")}.log',
              configfile=args.logcfg)
    log = getLogger('mkidpipe')

    if args.verbose:
        getLogger('mkidpipe').setLevel('DEBUG')
        getLogger('mkidpipeline').setLevel('DEBUG')
        getLogger('mkidcore').setLevel('DEBUG')

    if args.init:
        defstr = lambda x: f"{x}_default.yaml" if os.path.exists(f"{x}.yaml") else f"{x}.yaml"
        default_pipe_config = pipe.generate_default_config()
        with open(defstr('pipe'), 'w') as f:
            config.yaml.dump(default_pipe_config, f)

        sample_data = pipe.generate_sample_data()
        config.dump_dataconfig(sample_data, defstr('data'))

        sample_out = pipe.generate_sample_output()
        with open(defstr('out'), 'w') as f:
            config.yaml.dump(sample_out, f)
        sys.exit(0)

    config.configure_pipeline(args.pipe_cfg)
    outputs = config.MKIDOutputCollection(args.out_cfg, datafile=args.data_cfg)
    dataset = outputs.dataset

    if args.make_paths:
        config.make_paths(output_collection=outputs)

    if args.vet:
        config.report_vetting(outputs)
        sys.exit(0)

    if args.info:
        config.inspect_database(detailed=args.verbose)

    if args.single_step:
        try:
            pipe.PIPELINE_STEPS[args.single_step].fetch(dataset)
        except AttributeError:
            pass
        try:
            pipe.PIPELINE_STEPS[args.single_step].apply(dataset)
        except AttributeError:
            pass

    if args.makeout:
        # [] denote optional
        # build, meta, wave, pix -> wcs
        # build, meta, wave, pix, [flat] ->  spec
        # build, meta, [lin, wave, pix, cr, flat] -> image / movie
        # build, meta, [lin], wave, [pix, cr] -> flat
        # build, meta -> wave
        errors = outputs.validate(return_errors=True)
        if errors:
            getLogger('mkidpipeline').critical('Validation failed. Errors: \n\t'+'\n\t'.join(errors))
            sys.exit(0)
        #0
        steps.buildhdf.buildtables(outputs.input_timeranges)
        #1
        # pipe.batch_apply_metadata(outputs)
        #2
        steps.wavecal.fetch(outputs.wavecals)
        # steps.wavecal._loaded_solutions = {}
        # pipe.batch_applier(steps.lincal.apply, outputs.to_lincal)
        #3
        # pipe.batch_applier(steps.wavecal.apply, outputs.to_wavecal)
        # pipe.batch_apply_wavecals(outputs.to_wavecal)
        #4
        pipe.batch_applier(steps.pixcal.apply, outputs.to_pixcal)
        # pipe.batch_applier(steps.cosmiccal.apply, outputs.to_cosmiccal)
        #5
        # steps.flatcal.fetch(outputs.flatcals)
        #6
        # pipe.batch_applier(steps.flatcal.apply, outputs.to_flatcal)
        # steps.wcscal.fetch(outputs.wcscals)
        #7
        # steps.output.generate(outputs)
        #8
        # steps.speccal.fetch(outputs.speccals)
