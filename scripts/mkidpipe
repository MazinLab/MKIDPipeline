#!/usr/bin/env python3
import argparse
import os
import sys
import pkg_resources as pkg

import mkidcore
import mkidcore.config
from mkidcore.corelog import getLogger
import mkidpipeline.pipeline as pipe
import mkidpipeline.config as config
import mkidpipeline.steps as steps

if __name__ == "__main__":
    # read in command line arguments
    parser = argparse.ArgumentParser(description='MKID Pipeline CLI')
    parser.add_argument('-o', type=str, help='An output specification file', default='out.yaml', dest='out_cfg')
    parser.add_argument('-p', type=str, help='A pipeline config file', default='pipe.yaml', dest='pipe_cfg')
    parser.add_argument('-d', type=str, help='A input config file', default='data.yaml', dest='data_cfg')
    parser.add_argument('--vet',  action='store_true', help='Check pipeline configuration', default=False)
    parser.add_argument('--init', action='store_true', help='Setup the pipeline, clobbers files freely')
    parser.add_argument('--verbose', action='store_true', help='Verbose')
    parser.add_argument('--run-step', dest='single_step', help='Run a single named step', type=str)
    parser.add_argument('--make-dir', dest='make_paths', help='Create all needed directories', action='store_true')
    parser.add_argument('--info', dest='info', help='Report information about the configuration', action='store_true')

    getLogger('mkidcore').setLevel('INFO')
    log = getLogger('mkidpipeline')
    log.setLevel('INFO')

    args = parser.parse_args()
    if args.verbose:
        log.setLevel('DEBUG')
        getLogger('mkidcore').setLevel('DEBUG')
    else:
        pipe.getLogger('mkidpipeline.steps').setLevel('INFO')
        pipe.getLogger('mkidpipeline.hdf').setLevel('INFO')

    if args.init:
        default_pipe_config = pipe.generate_default_config()
        with open('pipe.yaml', 'w') as f:
            config.yaml.dump(default_pipe_config, f)

        sample_data = pipe.generate_sample_data()
        config.dump_dataconfig(sample_data, 'data.yaml')

        sample_out = pipe.generate_sample_output()
        with open('out.yaml', 'w') as f:
            config.yaml.dump(sample_out, f)

    config.configure_pipeline(args.pipe_cfg)
    outputs = config.MKIDOutputCollection(args.out_cfg, datafile=args.data_cfg)
    dataset = outputs.dataset

    if args.make_paths:
        config.make_paths(output_collection=outputs)

    if args.vet:
        for x in outputs:
            print(x._vet())
        for x in dataset:
            print(x._vet())
        sys.exit(0)

    if args.info:
        config.inspect_database(detailed=args.verbose)

    if args.single_step:
        pipe.PIPELINE_STEPS[args.single_step].run(dataset)

    #0
    steps.buildhdf.buildtables(outputs.input_timeranges)
    #1
    pipe.batch_apply_metadata(outputs)
    #2
    steps.wavecal.fetch(outputs.wavecals)
    pipe.batch_apply_lincals(outputs.to_lincal)
    #3
    pipe.batch_apply_wavecals(outputs.to_wavecal)
    #4
    pipe.batch_apply_pixcals(outputs.to_pixcal)
    pipe.batch_apply_cosmiccals(outputs.to_cosmiccal)
    #5
    steps.flatcal.fetch(outputs.flatcals)
    #6
    pipe.batch_apply_flatcals(outputs.to_flatcal)
    #steps.wcscal.fetch(outputs.wcscals)
    #7
    pipe.generate_outputs(outputs)
    #8
    steps.speccal.fetch(outputs.speccals)


    # pipe.run_stage1(outputs.dataset)
    pipe.generate_outputs(outputs)

    # build, meta, wave, pix -> wcs
    # build, meta, wave, pix, [flat] ->  spec
    # build, meta, [cr, lin, wave, pix, flat] -> image / movie
    # build, meta, [cr, lin], wave, [pix] -> flat
    # build, meta -> wave